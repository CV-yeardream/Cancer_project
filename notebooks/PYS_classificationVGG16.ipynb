{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\y0010\\AppData\\Local\\Temp\\ipykernel_22784\\3763141526.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2543099881527163823\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3667263488\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 10794082353415480800\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "import PIL\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras import models, layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, ZeroPadding2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB6, ResNet50V2\n",
    "#from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size: 한번에 forward & Backword 하는 샘플의 수\n",
    "batch_size = 32\n",
    "\n",
    "# Training 수\n",
    "epochs = 50\n",
    "\n",
    "# Weight 조절 parameter\n",
    "LearningRate = 1e-3 # 0.001\n",
    "Decay = 1e-6\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디렉토리 경로 설정 필요\n",
    "CurrentDirectory = \"../\"\n",
    "\n",
    "train_directory = CurrentDirectory + 'data/TRAIN/'\n",
    "test_directory  = CurrentDirectory + 'data/TEST/'\n",
    "model_directory = CurrentDirectory + 'MODEL/'\n",
    "tensorboard_directory = CurrentDirectory + 'Tensorboard'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\y0010\\anaconda3\\envs\\CV2\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 모델 Return\n",
    "VGG16Model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_tensor=None, input_shape=(img_width,img_height,3), pooling=None)\n",
    "x = GlobalAveragePooling2D()(VGG16Model.output)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "DeepLearning = Model(inputs=VGG16Model.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "DeepLearning.compile(optimizer=\n",
    "         SGD(lr=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['acc']\n",
    ") # 나이를, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online-augmentation 적용 Generator\n",
    "# 1. 이미지를 전부다 불러서 램 (메모리)에 올릴 수 없기 때문\n",
    "# 2. 이미지는 Augmentation을 해주는게 좋아서\n",
    "\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.10) # Train / Validation\n",
    "\n",
    "# Online-augmentation 비적용 Generator (Test용)\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10255 images belonging to 2 classes.\n",
      "Found 1138 images belonging to 2 classes.\n",
      "Found 1166 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generator의 instance 생성 (Train)\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= \"categorical\",\n",
    "    subset = \"training\")\n",
    "\n",
    "VALID_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    train_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= \"categorical\",\n",
    "    subset = \"validation\")\n",
    "\n",
    "# Generator의 instance 생성 (Test)\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode= \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath=model_directory+'VGG16-{epoch:03d}-{val_loss:.4f}-{val_acc:.4f}.hdf5',\n",
    "            monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# 학습과정 진행사항 확인\n",
    "TB = TensorBoard(log_dir=tensorboard_directory, write_graph=True, write_images=True)\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, TB, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\y0010\\anaconda3\\envs\\CV2\\lib\\site-packages\\keras\\preprocessing\\image.py:1663: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "c:\\Users\\y0010\\anaconda3\\envs\\CV2\\lib\\site-packages\\keras\\preprocessing\\image.py:1671: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.5055 - acc: 0.7878\n",
      "Epoch 1: val_acc improved from -inf to 0.79086, saving model to ../MODEL\\VGG16-001-0.5125-0.7909.hdf5\n",
      "321/321 [==============================] - 278s 803ms/step - loss: 0.5055 - acc: 0.7878 - val_loss: 0.5125 - val_acc: 0.7909 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.4731 - acc: 0.7987\n",
      "Epoch 2: val_acc did not improve from 0.79086\n",
      "321/321 [==============================] - 238s 741ms/step - loss: 0.4731 - acc: 0.7987 - val_loss: 0.5315 - val_acc: 0.7909 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.4449 - acc: 0.8134\n",
      "Epoch 3: val_acc did not improve from 0.79086\n",
      "321/321 [==============================] - 227s 707ms/step - loss: 0.4449 - acc: 0.8134 - val_loss: 0.5385 - val_acc: 0.7671 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.4208 - acc: 0.8221\n",
      "Epoch 4: val_acc did not improve from 0.79086\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "321/321 [==============================] - 228s 710ms/step - loss: 0.4208 - acc: 0.8221 - val_loss: 0.5161 - val_acc: 0.7882 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3971 - acc: 0.8298\n",
      "Epoch 5: val_acc improved from 0.79086 to 0.79174, saving model to ../MODEL\\VGG16-005-0.5004-0.7917.hdf5\n",
      "321/321 [==============================] - 405s 1s/step - loss: 0.3971 - acc: 0.8298 - val_loss: 0.5004 - val_acc: 0.7917 - lr: 8.0000e-04\n",
      "Epoch 6/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3843 - acc: 0.8376\n",
      "Epoch 6: val_acc improved from 0.79174 to 0.80492, saving model to ../MODEL\\VGG16-006-0.5012-0.8049.hdf5\n",
      "321/321 [==============================] - 590s 2s/step - loss: 0.3843 - acc: 0.8376 - val_loss: 0.5012 - val_acc: 0.8049 - lr: 8.0000e-04\n",
      "Epoch 7/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3748 - acc: 0.8418\n",
      "Epoch 7: val_acc improved from 0.80492 to 0.81107, saving model to ../MODEL\\VGG16-007-0.4664-0.8111.hdf5\n",
      "321/321 [==============================] - 411s 1s/step - loss: 0.3748 - acc: 0.8418 - val_loss: 0.4664 - val_acc: 0.8111 - lr: 8.0000e-04\n",
      "Epoch 8/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3658 - acc: 0.8492\n",
      "Epoch 8: val_acc did not improve from 0.81107\n",
      "321/321 [==============================] - 164s 510ms/step - loss: 0.3658 - acc: 0.8492 - val_loss: 0.5030 - val_acc: 0.7830 - lr: 8.0000e-04\n",
      "Epoch 9/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3585 - acc: 0.8546\n",
      "Epoch 9: val_acc did not improve from 0.81107\n",
      "321/321 [==============================] - 166s 516ms/step - loss: 0.3585 - acc: 0.8546 - val_loss: 0.5270 - val_acc: 0.8049 - lr: 8.0000e-04\n",
      "Epoch 10/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3455 - acc: 0.8584\n",
      "Epoch 10: val_acc did not improve from 0.81107\n",
      "321/321 [==============================] - 165s 515ms/step - loss: 0.3455 - acc: 0.8584 - val_loss: 0.4645 - val_acc: 0.8084 - lr: 8.0000e-04\n",
      "Epoch 11/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3423 - acc: 0.8633\n",
      "Epoch 11: val_acc did not improve from 0.81107\n",
      "321/321 [==============================] - 167s 520ms/step - loss: 0.3423 - acc: 0.8633 - val_loss: 0.4594 - val_acc: 0.8084 - lr: 8.0000e-04\n",
      "Epoch 12/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3328 - acc: 0.8617\n",
      "Epoch 12: val_acc improved from 0.81107 to 0.81547, saving model to ../MODEL\\VGG16-012-0.4714-0.8155.hdf5\n",
      "321/321 [==============================] - 167s 520ms/step - loss: 0.3328 - acc: 0.8617 - val_loss: 0.4714 - val_acc: 0.8155 - lr: 8.0000e-04\n",
      "Epoch 13/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3262 - acc: 0.8658\n",
      "Epoch 13: val_acc did not improve from 0.81547\n",
      "321/321 [==============================] - 167s 520ms/step - loss: 0.3262 - acc: 0.8658 - val_loss: 0.5172 - val_acc: 0.8111 - lr: 8.0000e-04\n",
      "Epoch 14/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3203 - acc: 0.8665\n",
      "Epoch 14: val_acc did not improve from 0.81547\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "321/321 [==============================] - 166s 516ms/step - loss: 0.3203 - acc: 0.8665 - val_loss: 0.5046 - val_acc: 0.7812 - lr: 8.0000e-04\n",
      "Epoch 15/15\n",
      "321/321 [==============================] - ETA: 0s - loss: 0.3124 - acc: 0.8709\n",
      "Epoch 15: val_acc did not improve from 0.81547\n",
      "321/321 [==============================] - 166s 517ms/step - loss: 0.3124 - acc: 0.8709 - val_loss: 0.4471 - val_acc: 0.8155 - lr: 6.4000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23e5ae556a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Training Start\n",
    "DeepLearning.fit(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        # steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        \n",
    "        epochs=15,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=VALID_GENERATOR)\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('CV2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdcd5b0206629939f51d5066d17712903ce8e88d008384575a999527a8ab4910"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
